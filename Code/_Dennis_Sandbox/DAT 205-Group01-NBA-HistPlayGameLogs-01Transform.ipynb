{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 205 Project - Transform data\n",
    "## By Dennis Hung\n",
    "## Version 1\n",
    "## Code DRAFT 2021-03-11\n",
    "\n",
    "## Updates\n",
    "#### \n"
   ]
  },
  {
   "source": [
    "##  Reference\n",
    "\n",
    "#### How to Get NBA Data Using the nba_api Python Module (Beginner). Retrieved from Plyaing Numbers: \n",
    "\n",
    "https://www.playingnumbers.com/2019/12/how-to-get-nba-data-using-the-nba_api-python-module-beginner/\n",
    "\n",
    "#### Patel, S. (2020, August 19). swar / nba_api. Retrieved from GitHub: \n",
    "\n",
    "https://github.com/swar/nba_api/blob/master/docs/table_of_contents.md\n",
    "\n",
    "#### Issues\n",
    "\n",
    "https://github.com/swar/nba_api/issues/124\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Note: \n",
    "#### This code relies on the CSV output from \"DAT 205-Group01-NBA-HistPlayGameLogs.ipynb\" as the dataset for this transformation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Section 0: Function definitions\n",
    "\n",
    "hms_string(sec_elapsed)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60))/60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h,m,s)\n",
    "\n",
    "# Null field analysis\n",
    "def nullFieldAnalysis(df):\n",
    "    df_missingDataInfo = pd.DataFrame({'Count': df.isnull().sum(), 'Percent': 100*df.isnull().sum()/len(df)})\n",
    "    #Printing the columns with over XX% of missing values (ie 60 = 60%) This is set to 0 for 0%\n",
    "    null_threshold = 0 \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"==== Null value analysis ====\")\n",
    "    return df_missingDataInfo[df_missingDataInfo['Percent'] > null_threshold].sort_values(by=['Percent'])\n"
   ]
  },
  {
   "source": [
    "# Section 1: Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized required packages\n",
    "# Standard packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Graphing packages\n",
    "import seaborn as sns\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "# import matplotlib.lines as mlines\n",
    "\n",
    "# Data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Modeling packages\n",
    "# import tensorflow as tf\n",
    "# import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Regression modeling\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Confusion matrix, Accuracy, sensitivity and specificity\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "# from sklearn.feature_selection import VarianceThreshold \n",
    "from sklearn.feature_selection import RFE \n",
    "# from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Clustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# Following code is being deprecated\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# Initialize variables if there is any debugging required\n",
    "# Insert following line and activate the debugging.\n",
    "# # VALIDATION CODE \n",
    "# if debug_active == 'yes':\n",
    "# \n",
    "# Use \"display(df)\"\" if the result command is \"df\" to retain the same format\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "source": [
    "# Section 2: Configuration of variables\n",
    "\n",
    "Must manually set the following variables\n",
    "\n",
    "gameTypeListed as one of the following: 'Pre Season', 'Regular Season', 'Playoffs'\n",
    "\n",
    "seasonsListed for the game season in this format '2015-16'. Have at least 2 values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick who is running the code and comment out the others\n",
    "# coder = 'bhavika'\n",
    "# coder = 'cindy'\n",
    "coder = 'dennis'\n",
    "\n",
    "\n",
    "debug_active = 'yes'\n",
    "loop_max = 100\n",
    "# showNumRecs = 15\n",
    "test_size_val = 0.50\n",
    "random_state_val = 42\n",
    "numFormat = '{:.4f}'\n",
    "\n",
    "# Setup file name for csv or Excel (.xlsx)\n",
    "if coder == 'bhavika':\n",
    "    filename = 'D:/McMaster/DAT205/Capstone/Data/HistoricalGameLogs_2004-05_to_2019-20_ALL.csv'\n",
    "elif coder == 'dennis':\n",
    "    filename = './HistoricalGameLogs_2007-08_to_2008-09_ALL.csv'\n",
    "\n",
    "# filename = filename + seasonStart + '_to_' + seasonEnd + '_' + gameType + '.csv'\n",
    "# filename = filename + seasonStart + '_to_' + seasonEnd + '_ALL' + '.csv'\n",
    "\n",
    "\n",
    "# Update player stats per game each season\n",
    "\n",
    "gameTypeListed = ['Pre Season', 'Regular Season', 'Playoffs']\n",
    "\n",
    "# Option 1: For all currently possible seasons\n",
    "# seasonsListed = ['1946-47', '1947-48', '1948-49', '1949-50'\n",
    "# , '1950-51', '1951-52', '1952-53', '1953-54', '1954-55', '1955-56', '1956-57', '1957-58', '1958-59', '1959-60'\n",
    "# , '1960-61', '1961-62', '1962-63', '1963-64', '1964-65', '1965-66', '1966-67', '1967-68', '1968-69', '1969-70'\n",
    "# , '1970-71', '1971-72', '1972-73', '1973-74', '1974-75', '1975-76', '1976-77', '1977-78', '1978-79', '1979-80'\n",
    "# , '1980-81', '1981-82', '1982-83', '1983-84', '1984-85', '1985-86', '1986-87', '1987-88', '1988-89', '1989-90'\n",
    "# , '1990-91', '1991-92', '1992-93', '1993-94', '1994-95', '1995-96', '1996-97', '1997-98', '1998-99', '1999-00'\n",
    "# , '2000-01', '2001-02', '2002-03', '2003-04', '2004-05', '2005-06', '2006-07', '2007-08', '2008-09', '2009-10'\n",
    "# , '2010-11', '2011-12', '2012-13', '2013-14', '2014-15', '2015-16', '2016-17', '2017-18', '2018-19', '2019-20'\n",
    "# , '2020-21']\n",
    "\n",
    "seasonsListed = ['2004-05', '2005-06', '2006-07', '2007-08', '2008-09', '2009-10'\n",
    ", '2010-11', '2011-12', '2012-13', '2013-14', '2014-15', '2015-16', '2016-17', '2017-18', '2018-19', '2019-20']\n",
    "\n",
    "seasonStart = seasonsListed[0]\n",
    "seasonEnd = seasonsListed[-1]\n",
    "\n",
    "# Request info for each season in the list\n",
    "df_gamelogs_player = []\n",
    "countFirstYear = 0"
   ]
  },
  {
   "source": [
    "# Section 3: Upload the dataset and initial analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      SEASON_YEAR  PLAYER_ID       PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION  \\\n0         2007-08     200759    Cedric Simmons  1610612739               CLE   \n1         2007-08       1088     Chucky Atkins  1610612743               DEN   \n2         2007-08     201191     JamesOn Curry  1610612741               CHI   \n3         2007-08       1956        Ira Newble  1610612739               CLE   \n4         2007-08       2743    Kris Humphries  1610612761               TOR   \n...           ...        ...               ...         ...               ...   \n58283     2008-09     200796         Leon Powe  1610612738               BOS   \n58284     2008-09       1888  Richard Hamilton  1610612765               DET   \n58285     2008-09        703       Kurt Thomas  1610612759               SAS   \n58286     2008-09     101112     Channing Frye  1610612757               POR   \n58287     2008-09       1630       Mikki Moore  1610612738               BOS   \n\n                    TEAM_NAME     GAME_ID            GAME_DATE      MATCHUP  \\\n0         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n1              Denver Nuggets  0010700106  2007-10-25T00:00:00    DEN @ PHX   \n2               Chicago Bulls  0010700109  2007-10-25T00:00:00  CHI vs. MIL   \n3         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n4             Toronto Raptors  0010700104  2007-10-25T00:00:00  TOR vs. CLE   \n...                       ...         ...                  ...          ...   \n58283          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n58284         Detroit Pistons  0040800101  2009-04-18T00:00:00    DET @ CLE   \n58285       San Antonio Spurs  0040800161  2009-04-18T00:00:00  SAS vs. DAL   \n58286  Portland Trail Blazers  0040800171  2009-04-18T00:00:00  POR vs. HOU   \n58287          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n\n      WL  ...  STL  BLK  BLKA  PF  PFD  PTS  PLUS_MINUS  DD2  TD3   Game_Type  \n0      L  ...    0    0     0   2    0    0         -10    0    0  Pre Season  \n1      L  ...    0    0     0   0    0    2           0    0    0  Pre Season  \n2      W  ...    0    0     0   1    0    0           4    0    0  Pre Season  \n3      L  ...    0    0     0   0    0    0          -2    0    0  Pre Season  \n4      W  ...    1    0     0   4    2   11          23    0    0  Pre Season  \n...   ..  ...  ...  ...   ...  ..  ...  ...         ...  ...  ...         ...  \n58283  L  ...    0    0     0   2    6    8         -10    0    0    Playoffs  \n58284  L  ...    0    0     0   1    2   15         -19    0    0    Playoffs  \n58285  L  ...    1    0     0   1    0    0          -9    0    0    Playoffs  \n58286  L  ...    0    0     0   4    1    4         -15    0    0    Playoffs  \n58287  L  ...    0    0     0   0    0    2          -6    0    0    Playoffs  \n\n[58288 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEASON_YEAR</th>\n      <th>PLAYER_ID</th>\n      <th>PLAYER_NAME</th>\n      <th>TEAM_ID</th>\n      <th>TEAM_ABBREVIATION</th>\n      <th>TEAM_NAME</th>\n      <th>GAME_ID</th>\n      <th>GAME_DATE</th>\n      <th>MATCHUP</th>\n      <th>WL</th>\n      <th>...</th>\n      <th>STL</th>\n      <th>BLK</th>\n      <th>BLKA</th>\n      <th>PF</th>\n      <th>PFD</th>\n      <th>PTS</th>\n      <th>PLUS_MINUS</th>\n      <th>DD2</th>\n      <th>TD3</th>\n      <th>Game_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-08</td>\n      <td>200759</td>\n      <td>Cedric Simmons</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-08</td>\n      <td>1088</td>\n      <td>Chucky Atkins</td>\n      <td>1610612743</td>\n      <td>DEN</td>\n      <td>Denver Nuggets</td>\n      <td>0010700106</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>DEN @ PHX</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-08</td>\n      <td>201191</td>\n      <td>JamesOn Curry</td>\n      <td>1610612741</td>\n      <td>CHI</td>\n      <td>Chicago Bulls</td>\n      <td>0010700109</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CHI vs. MIL</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-08</td>\n      <td>1956</td>\n      <td>Ira Newble</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-08</td>\n      <td>2743</td>\n      <td>Kris Humphries</td>\n      <td>1610612761</td>\n      <td>TOR</td>\n      <td>Toronto Raptors</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>TOR vs. CLE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58283</th>\n      <td>2008-09</td>\n      <td>200796</td>\n      <td>Leon Powe</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n    </tr>\n    <tr>\n      <th>58284</th>\n      <td>2008-09</td>\n      <td>1888</td>\n      <td>Richard Hamilton</td>\n      <td>1610612765</td>\n      <td>DET</td>\n      <td>Detroit Pistons</td>\n      <td>0040800101</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>DET @ CLE</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15</td>\n      <td>-19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n    </tr>\n    <tr>\n      <th>58285</th>\n      <td>2008-09</td>\n      <td>703</td>\n      <td>Kurt Thomas</td>\n      <td>1610612759</td>\n      <td>SAS</td>\n      <td>San Antonio Spurs</td>\n      <td>0040800161</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>SAS vs. DAL</td>\n      <td>L</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n    </tr>\n    <tr>\n      <th>58286</th>\n      <td>2008-09</td>\n      <td>101112</td>\n      <td>Channing Frye</td>\n      <td>1610612757</td>\n      <td>POR</td>\n      <td>Portland Trail Blazers</td>\n      <td>0040800171</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>POR vs. HOU</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n    </tr>\n    <tr>\n      <th>58287</th>\n      <td>2008-09</td>\n      <td>1630</td>\n      <td>Mikki Moore</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n    </tr>\n  </tbody>\n</table>\n<p>58288 rows × 35 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "(58288, 35)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the dataset\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 58288 entries, 0 to 58287\nData columns (total 35 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   SEASON_YEAR        58288 non-null  object \n 1   PLAYER_ID          58288 non-null  int64  \n 2   PLAYER_NAME        58093 non-null  object \n 3   TEAM_ID            58288 non-null  int64  \n 4   TEAM_ABBREVIATION  58288 non-null  object \n 5   TEAM_NAME          58288 non-null  object \n 6   GAME_ID            58288 non-null  object \n 7   GAME_DATE          58288 non-null  object \n 8   MATCHUP            58288 non-null  object \n 9   WL                 58239 non-null  object \n 10  MIN                58288 non-null  float64\n 11  FGM                58288 non-null  int64  \n 12  FGA                58288 non-null  int64  \n 13  FG_PCT             58288 non-null  float64\n 14  FG3M               58288 non-null  int64  \n 15  FG3A               58288 non-null  int64  \n 16  FG3_PCT            58288 non-null  float64\n 17  FTM                58288 non-null  int64  \n 18  FTA                58288 non-null  int64  \n 19  FT_PCT             58288 non-null  float64\n 20  OREB               58288 non-null  int64  \n 21  DREB               58288 non-null  int64  \n 22  REB                58288 non-null  int64  \n 23  AST                58288 non-null  int64  \n 24  TOV                58288 non-null  int64  \n 25  STL                58288 non-null  int64  \n 26  BLK                58288 non-null  int64  \n 27  BLKA               58288 non-null  int64  \n 28  PF                 58288 non-null  int64  \n 29  PFD                58288 non-null  int64  \n 30  PTS                58288 non-null  int64  \n 31  PLUS_MINUS         58288 non-null  int64  \n 32  DD2                58288 non-null  int64  \n 33  TD3                58288 non-null  int64  \n 34  Game_Type          58288 non-null  object \ndtypes: float64(4), int64(22), object(9)\nmemory usage: 15.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# load the CSV or Excel file \n",
    "# Note the other option in Jupyter Notebook is to use the upload the csv files before running the code\n",
    "\n",
    "# lst of column names which needs to be string\n",
    "lst_str_cols = ['GAME_ID']\n",
    "# use dictionary comprehension to make dict of dtypes\n",
    "dict_dtypes = {x : 'str'  for x in lst_str_cols}\n",
    "# use dict on dtypes\n",
    "df = pd.read_csv(filename, dtype=dict_dtypes)\n",
    "\n",
    "# Excel file import\n",
    "# df = pd.read_excel(filename)\n",
    "\n",
    "\n",
    "# Remove duplicate index from import\n",
    "unwanted_list = ['Unnamed: 0']\n",
    "\n",
    "X_headers_list = df.columns.tolist()\n",
    "\n",
    "for x in unwanted_list:\n",
    "    X_headers_list.remove(x)\n",
    "\n",
    "# Display current dataframe\n",
    "df_Initial = df[X_headers_list]\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Initial)\n",
    "    # Examine shape of dataframe\n",
    "    display(df_Initial.shape)\n",
    "    # Examine the type of attributes in the dataframe\n",
    "    print(\"Shape of the dataset\")\n",
    "    df_Initial.info()\n",
    "    # Describe the numerical data\n",
    "    df_Initial.describe()\n",
    "    \n"
   ]
  },
  {
   "source": [
    "## Initial Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VALIDATION CODE\n['SEASON_YEAR', 'PLAYER_NAME', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_ID', 'GAME_DATE', 'MATCHUP', 'WL', 'Game_Type']\n\n\n==== Description of the categorical features ====\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       SEASON_YEAR  PLAYER_NAME TEAM_ABBREVIATION           TEAM_NAME  \\\ncount        58288        58093             58288               58288   \nunique           2          638                43                  43   \ntop        2007-08  Kobe Bryant               LAL  Los Angeles Lakers   \nfreq         29259          221              2330                2330   \n\n           GAME_ID            GAME_DATE    MATCHUP     WL       Game_Type  \ncount        58288                58288      58288  58239           58288  \nunique        2847                  457       1890      2               3  \ntop     0010700007  2009-01-02T00:00:00  UTA @ LAL      W  Regular Season  \nfreq            33                  304        137  29190           49515  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEASON_YEAR</th>\n      <th>PLAYER_NAME</th>\n      <th>TEAM_ABBREVIATION</th>\n      <th>TEAM_NAME</th>\n      <th>GAME_ID</th>\n      <th>GAME_DATE</th>\n      <th>MATCHUP</th>\n      <th>WL</th>\n      <th>Game_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>58288</td>\n      <td>58093</td>\n      <td>58288</td>\n      <td>58288</td>\n      <td>58288</td>\n      <td>58288</td>\n      <td>58288</td>\n      <td>58239</td>\n      <td>58288</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>638</td>\n      <td>43</td>\n      <td>43</td>\n      <td>2847</td>\n      <td>457</td>\n      <td>1890</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>2007-08</td>\n      <td>Kobe Bryant</td>\n      <td>LAL</td>\n      <td>Los Angeles Lakers</td>\n      <td>0010700007</td>\n      <td>2009-01-02T00:00:00</td>\n      <td>UTA @ LAL</td>\n      <td>W</td>\n      <td>Regular Season</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>29259</td>\n      <td>221</td>\n      <td>2330</td>\n      <td>2330</td>\n      <td>33</td>\n      <td>304</td>\n      <td>137</td>\n      <td>29190</td>\n      <td>49515</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n==== Null value analysis ====\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Count   Percent\n",
       "WL              49  0.084065\n",
       "PLAYER_NAME    195  0.334546"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Count</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>WL</th>\n      <td>49</td>\n      <td>0.084065</td>\n    </tr>\n    <tr>\n      <th>PLAYER_NAME</th>\n      <td>195</td>\n      <td>0.334546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Display the headers of columns that use descriptive or non-numerical values\n",
    "categorical_Features = df_Initial.dtypes[df_Initial.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print(\"VALIDATION CODE\")\n",
    "    print(categorical_Features)\n",
    "\n",
    "# Describe the categorical data\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"==== Description of the categorical features ====\")\n",
    "display(df_Initial[categorical_Features].describe())\n",
    "\n",
    "# # Null field analysis\n",
    "nullFieldAnalysis(df_Initial)\n",
    "# # Null field analysis\n",
    "# df_missingDataInfo = pd.DataFrame({'Count': df_Initial.isnull().sum(), 'Percent': 100*df_Initial.isnull().sum()/len(df)})\n",
    "\n",
    "# #Printing the columns with over XX% of missing values (ie 60 = 60%) This is set to 0 for 0%\n",
    "# null_threshold = 0 \n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"==== Null value analysis ====\")\n",
    "# df_missingDataInfo[df_missingDataInfo['Percent'] > null_threshold].sort_values(by=['Percent'])"
   ]
  },
  {
   "source": [
    "# "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Section 4: Transforming/cleansing the data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data cleansing of nulls (Not working)\n",
    "\n",
    "## Correction to missing PreSeason games WL values only \n",
    "\n",
    "49 records \n",
    "\n",
    "2007-08 \n",
    "GAME_ID 0010700072 / 2007-10-19\n",
    "BOS vs NJN   W 36 to L 33\n",
    "\n",
    "2008-09 \n",
    "GAME_ID 0010800035 / 2008-10-11\n",
    "DEN vs PHX   W 77 to L 72\n",
    "Note some player game data seems missing\n",
    "\n",
    "## Corrected missing player name data\n",
    "\n",
    "740 records (727 preseason and 13 regular season)\n",
    "\n",
    "This is not important as the player names are excluded from the analysis\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF = df_Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_missingDataInfo[df_missingDataInfo['Percent'] > null_threshold].loc[df_missingDataInfo[]]\n",
    "\n",
    "# missingDataInfo_List = df_missingDataInfo.loc[df_missingDataInfo['Count']>0].index.tolist()\n",
    "# # ['PLAYER_NAME', 'WL']\n",
    "\n",
    "# numOfRows = len(df_missingDataInfo.index)\n",
    "\n",
    "# for missingDataInfo_Value in missingDataInfo_List:\n",
    "#     df_missingDataInfo[df_missingDataInfo[index] = missingDataInfo_Value]\n",
    "\n",
    "\n",
    "# # Pull player data\n",
    "# from nba_api.stats.static import players\n",
    "# player_dict = players.get_players()\n",
    "\n",
    "\n",
    "# # Use ternary operator or write function \n",
    "# # Names are case sensitive\n",
    "# bron = [player for player in player_dict if player['full_name'] == 'LeBron James'][0]\n",
    "# bron_id = bron['id']\n",
    "\n",
    "# # find team Ids\n",
    "# from nba_api.stats.static import teams \n",
    "# teams = teams.get_teams()\n",
    "# GSW = [x for x in teams if x['full_name'] == 'Golden State Warriors'][0]\n",
    "# GSW_id = GSW['id']"
   ]
  },
  {
   "source": [
    "## Enhance the data\n",
    "\n",
    "### PIE\n",
    "\n",
    "Name Player Impact Estimate \n",
    "\n",
    "Definition PIE measures a player's overall statistical contribution against the total statistics in games they play in. PIE yields results which are comparable to other advanced statistics (e.g. PER) using a simple formula.\n",
    "\n",
    "Formula (PTS + FGM + FTM - FGA - FTA + DREB + (.5 * OREB) + AST + STL + (.5 * BLK) - PF - TO) / (GmPTS + GmFGM + GmFTM - GmFGA - GmFTA + GmDREB + (.5 * GmOREB) + GmAST + GmSTL + (.5 * GmBLK) - GmPF - GmTO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "58288\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      SEASON_YEAR  PLAYER_ID       PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION  \\\n0         2007-08     200759    Cedric Simmons  1610612739               CLE   \n1         2007-08       1088     Chucky Atkins  1610612743               DEN   \n2         2007-08     201191     JamesOn Curry  1610612741               CHI   \n3         2007-08       1956        Ira Newble  1610612739               CLE   \n4         2007-08       2743    Kris Humphries  1610612761               TOR   \n...           ...        ...               ...         ...               ...   \n58283     2008-09     200796         Leon Powe  1610612738               BOS   \n58284     2008-09       1888  Richard Hamilton  1610612765               DET   \n58285     2008-09        703       Kurt Thomas  1610612759               SAS   \n58286     2008-09     101112     Channing Frye  1610612757               POR   \n58287     2008-09       1630       Mikki Moore  1610612738               BOS   \n\n                    TEAM_NAME     GAME_ID            GAME_DATE      MATCHUP  \\\n0         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n1              Denver Nuggets  0010700106  2007-10-25T00:00:00    DEN @ PHX   \n2               Chicago Bulls  0010700109  2007-10-25T00:00:00  CHI vs. MIL   \n3         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n4             Toronto Raptors  0010700104  2007-10-25T00:00:00  TOR vs. CLE   \n...                       ...         ...                  ...          ...   \n58283          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n58284         Detroit Pistons  0040800101  2009-04-18T00:00:00    DET @ CLE   \n58285       San Antonio Spurs  0040800161  2009-04-18T00:00:00  SAS vs. DAL   \n58286  Portland Trail Blazers  0040800171  2009-04-18T00:00:00  POR vs. HOU   \n58287          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n\n      WL  ...  BLK  BLKA  PF  PFD  PTS  PLUS_MINUS  DD2  TD3   Game_Type  \\\n0      L  ...    0     0   2    0    0         -10    0    0  Pre Season   \n1      L  ...    0     0   0    0    2           0    0    0  Pre Season   \n2      W  ...    0     0   1    0    0           4    0    0  Pre Season   \n3      L  ...    0     0   0    0    0          -2    0    0  Pre Season   \n4      W  ...    0     0   4    2   11          23    0    0  Pre Season   \n...   ..  ...  ...   ...  ..  ...  ...         ...  ...  ...         ...   \n58283  L  ...    0     0   2    6    8         -10    0    0    Playoffs   \n58284  L  ...    0     0   1    2   15         -19    0    0    Playoffs   \n58285  L  ...    0     0   1    0    0          -9    0    0    Playoffs   \n58286  L  ...    0     0   4    1    4         -15    0    0    Playoffs   \n58287  L  ...    0     0   0    0    2          -6    0    0    Playoffs   \n\n                           UID_STG  \n0      2007-0816106127390010700104  \n1      2007-0816106127430010700106  \n2      2007-0816106127410010700109  \n3      2007-0816106127390010700104  \n4      2007-0816106127610010700104  \n...                            ...  \n58283  2008-0916106127380040800111  \n58284  2008-0916106127650040800101  \n58285  2008-0916106127590040800161  \n58286  2008-0916106127570040800171  \n58287  2008-0916106127380040800111  \n\n[58288 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEASON_YEAR</th>\n      <th>PLAYER_ID</th>\n      <th>PLAYER_NAME</th>\n      <th>TEAM_ID</th>\n      <th>TEAM_ABBREVIATION</th>\n      <th>TEAM_NAME</th>\n      <th>GAME_ID</th>\n      <th>GAME_DATE</th>\n      <th>MATCHUP</th>\n      <th>WL</th>\n      <th>...</th>\n      <th>BLK</th>\n      <th>BLKA</th>\n      <th>PF</th>\n      <th>PFD</th>\n      <th>PTS</th>\n      <th>PLUS_MINUS</th>\n      <th>DD2</th>\n      <th>TD3</th>\n      <th>Game_Type</th>\n      <th>UID_STG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-08</td>\n      <td>200759</td>\n      <td>Cedric Simmons</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-08</td>\n      <td>1088</td>\n      <td>Chucky Atkins</td>\n      <td>1610612743</td>\n      <td>DEN</td>\n      <td>Denver Nuggets</td>\n      <td>0010700106</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>DEN @ PHX</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127430010700106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-08</td>\n      <td>201191</td>\n      <td>JamesOn Curry</td>\n      <td>1610612741</td>\n      <td>CHI</td>\n      <td>Chicago Bulls</td>\n      <td>0010700109</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CHI vs. MIL</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127410010700109</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-08</td>\n      <td>1956</td>\n      <td>Ira Newble</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-08</td>\n      <td>2743</td>\n      <td>Kris Humphries</td>\n      <td>1610612761</td>\n      <td>TOR</td>\n      <td>Toronto Raptors</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>TOR vs. CLE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127610010700104</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58283</th>\n      <td>2008-09</td>\n      <td>200796</td>\n      <td>Leon Powe</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n    <tr>\n      <th>58284</th>\n      <td>2008-09</td>\n      <td>1888</td>\n      <td>Richard Hamilton</td>\n      <td>1610612765</td>\n      <td>DET</td>\n      <td>Detroit Pistons</td>\n      <td>0040800101</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>DET @ CLE</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15</td>\n      <td>-19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127650040800101</td>\n    </tr>\n    <tr>\n      <th>58285</th>\n      <td>2008-09</td>\n      <td>703</td>\n      <td>Kurt Thomas</td>\n      <td>1610612759</td>\n      <td>SAS</td>\n      <td>San Antonio Spurs</td>\n      <td>0040800161</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>SAS vs. DAL</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127590040800161</td>\n    </tr>\n    <tr>\n      <th>58286</th>\n      <td>2008-09</td>\n      <td>101112</td>\n      <td>Channing Frye</td>\n      <td>1610612757</td>\n      <td>POR</td>\n      <td>Portland Trail Blazers</td>\n      <td>0040800171</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>POR vs. HOU</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127570040800171</td>\n    </tr>\n    <tr>\n      <th>58287</th>\n      <td>2008-09</td>\n      <td>1630</td>\n      <td>Mikki Moore</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n  </tbody>\n</table>\n<p>58288 rows × 36 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['SEASON_YEAR', 'PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID',\n       'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_ID', 'GAME_DATE', 'MATCHUP',\n       'WL', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM',\n       'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK',\n       'BLKA', 'PF', 'PFD', 'PTS', 'PLUS_MINUS', 'DD2', 'TD3', 'Game_Type',\n       'UID_STG'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "totalNumRec = df_TF.shape[0]\n",
    "print(totalNumRec)\n",
    "display(df_TF)\n",
    "print(df_TF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF = df_Initial\n",
    "\n",
    "# create UID_STG for SEASON_YEAR', 'TEAM_ID', 'GAME_ID'\n",
    "df_TF['UID_STG'] = 'new field'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      SEASON_YEAR  PLAYER_ID       PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION  \\\n0         2007-08     200759    Cedric Simmons  1610612739               CLE   \n1         2007-08       1088     Chucky Atkins  1610612743               DEN   \n2         2007-08     201191     JamesOn Curry  1610612741               CHI   \n3         2007-08       1956        Ira Newble  1610612739               CLE   \n4         2007-08       2743    Kris Humphries  1610612761               TOR   \n...           ...        ...               ...         ...               ...   \n58283     2008-09     200796         Leon Powe  1610612738               BOS   \n58284     2008-09       1888  Richard Hamilton  1610612765               DET   \n58285     2008-09        703       Kurt Thomas  1610612759               SAS   \n58286     2008-09     101112     Channing Frye  1610612757               POR   \n58287     2008-09       1630       Mikki Moore  1610612738               BOS   \n\n                    TEAM_NAME     GAME_ID            GAME_DATE      MATCHUP  \\\n0         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n1              Denver Nuggets  0010700106  2007-10-25T00:00:00    DEN @ PHX   \n2               Chicago Bulls  0010700109  2007-10-25T00:00:00  CHI vs. MIL   \n3         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n4             Toronto Raptors  0010700104  2007-10-25T00:00:00  TOR vs. CLE   \n...                       ...         ...                  ...          ...   \n58283          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n58284         Detroit Pistons  0040800101  2009-04-18T00:00:00    DET @ CLE   \n58285       San Antonio Spurs  0040800161  2009-04-18T00:00:00  SAS vs. DAL   \n58286  Portland Trail Blazers  0040800171  2009-04-18T00:00:00  POR vs. HOU   \n58287          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n\n      WL  ...  BLK  BLKA  PF  PFD  PTS  PLUS_MINUS  DD2  TD3   Game_Type  \\\n0      L  ...    0     0   2    0    0         -10    0    0  Pre Season   \n1      L  ...    0     0   0    0    2           0    0    0  Pre Season   \n2      W  ...    0     0   1    0    0           4    0    0  Pre Season   \n3      L  ...    0     0   0    0    0          -2    0    0  Pre Season   \n4      W  ...    0     0   4    2   11          23    0    0  Pre Season   \n...   ..  ...  ...   ...  ..  ...  ...         ...  ...  ...         ...   \n58283  L  ...    0     0   2    6    8         -10    0    0    Playoffs   \n58284  L  ...    0     0   1    2   15         -19    0    0    Playoffs   \n58285  L  ...    0     0   1    0    0          -9    0    0    Playoffs   \n58286  L  ...    0     0   4    1    4         -15    0    0    Playoffs   \n58287  L  ...    0     0   0    0    2          -6    0    0    Playoffs   \n\n                           UID_STG  \n0      2007-0816106127390010700104  \n1      2007-0816106127430010700106  \n2      2007-0816106127410010700109  \n3      2007-0816106127390010700104  \n4      2007-0816106127610010700104  \n...                            ...  \n58283  2008-0916106127380040800111  \n58284  2008-0916106127650040800101  \n58285  2008-0916106127590040800161  \n58286  2008-0916106127570040800171  \n58287  2008-0916106127380040800111  \n\n[58288 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEASON_YEAR</th>\n      <th>PLAYER_ID</th>\n      <th>PLAYER_NAME</th>\n      <th>TEAM_ID</th>\n      <th>TEAM_ABBREVIATION</th>\n      <th>TEAM_NAME</th>\n      <th>GAME_ID</th>\n      <th>GAME_DATE</th>\n      <th>MATCHUP</th>\n      <th>WL</th>\n      <th>...</th>\n      <th>BLK</th>\n      <th>BLKA</th>\n      <th>PF</th>\n      <th>PFD</th>\n      <th>PTS</th>\n      <th>PLUS_MINUS</th>\n      <th>DD2</th>\n      <th>TD3</th>\n      <th>Game_Type</th>\n      <th>UID_STG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-08</td>\n      <td>200759</td>\n      <td>Cedric Simmons</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-08</td>\n      <td>1088</td>\n      <td>Chucky Atkins</td>\n      <td>1610612743</td>\n      <td>DEN</td>\n      <td>Denver Nuggets</td>\n      <td>0010700106</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>DEN @ PHX</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127430010700106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-08</td>\n      <td>201191</td>\n      <td>JamesOn Curry</td>\n      <td>1610612741</td>\n      <td>CHI</td>\n      <td>Chicago Bulls</td>\n      <td>0010700109</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CHI vs. MIL</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127410010700109</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-08</td>\n      <td>1956</td>\n      <td>Ira Newble</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-08</td>\n      <td>2743</td>\n      <td>Kris Humphries</td>\n      <td>1610612761</td>\n      <td>TOR</td>\n      <td>Toronto Raptors</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>TOR vs. CLE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127610010700104</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58283</th>\n      <td>2008-09</td>\n      <td>200796</td>\n      <td>Leon Powe</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n    <tr>\n      <th>58284</th>\n      <td>2008-09</td>\n      <td>1888</td>\n      <td>Richard Hamilton</td>\n      <td>1610612765</td>\n      <td>DET</td>\n      <td>Detroit Pistons</td>\n      <td>0040800101</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>DET @ CLE</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15</td>\n      <td>-19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127650040800101</td>\n    </tr>\n    <tr>\n      <th>58285</th>\n      <td>2008-09</td>\n      <td>703</td>\n      <td>Kurt Thomas</td>\n      <td>1610612759</td>\n      <td>SAS</td>\n      <td>San Antonio Spurs</td>\n      <td>0040800161</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>SAS vs. DAL</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127590040800161</td>\n    </tr>\n    <tr>\n      <th>58286</th>\n      <td>2008-09</td>\n      <td>101112</td>\n      <td>Channing Frye</td>\n      <td>1610612757</td>\n      <td>POR</td>\n      <td>Portland Trail Blazers</td>\n      <td>0040800171</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>POR vs. HOU</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127570040800171</td>\n    </tr>\n    <tr>\n      <th>58287</th>\n      <td>2008-09</td>\n      <td>1630</td>\n      <td>Mikki Moore</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n  </tbody>\n</table>\n<p>58288 rows × 36 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(df_TF)\n",
    "df_TF.to_csv('DAT205_Output_TF.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      SEASON_YEAR  PLAYER_ID       PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION  \\\n0         2007-08     200759    Cedric Simmons  1610612739               CLE   \n1         2007-08       1088     Chucky Atkins  1610612743               DEN   \n2         2007-08     201191     JamesOn Curry  1610612741               CHI   \n3         2007-08       1956        Ira Newble  1610612739               CLE   \n4         2007-08       2743    Kris Humphries  1610612761               TOR   \n...           ...        ...               ...         ...               ...   \n58283     2008-09     200796         Leon Powe  1610612738               BOS   \n58284     2008-09       1888  Richard Hamilton  1610612765               DET   \n58285     2008-09        703       Kurt Thomas  1610612759               SAS   \n58286     2008-09     101112     Channing Frye  1610612757               POR   \n58287     2008-09       1630       Mikki Moore  1610612738               BOS   \n\n                    TEAM_NAME     GAME_ID            GAME_DATE      MATCHUP  \\\n0         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n1              Denver Nuggets  0010700106  2007-10-25T00:00:00    DEN @ PHX   \n2               Chicago Bulls  0010700109  2007-10-25T00:00:00  CHI vs. MIL   \n3         Cleveland Cavaliers  0010700104  2007-10-25T00:00:00    CLE @ TOR   \n4             Toronto Raptors  0010700104  2007-10-25T00:00:00  TOR vs. CLE   \n...                       ...         ...                  ...          ...   \n58283          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n58284         Detroit Pistons  0040800101  2009-04-18T00:00:00    DET @ CLE   \n58285       San Antonio Spurs  0040800161  2009-04-18T00:00:00  SAS vs. DAL   \n58286  Portland Trail Blazers  0040800171  2009-04-18T00:00:00  POR vs. HOU   \n58287          Boston Celtics  0040800111  2009-04-18T00:00:00  BOS vs. CHI   \n\n      WL  ...  BLK  BLKA  PF  PFD  PTS  PLUS_MINUS  DD2  TD3   Game_Type  \\\n0      L  ...    0     0   2    0    0         -10    0    0  Pre Season   \n1      L  ...    0     0   0    0    2           0    0    0  Pre Season   \n2      W  ...    0     0   1    0    0           4    0    0  Pre Season   \n3      L  ...    0     0   0    0    0          -2    0    0  Pre Season   \n4      W  ...    0     0   4    2   11          23    0    0  Pre Season   \n...   ..  ...  ...   ...  ..  ...  ...         ...  ...  ...         ...   \n58283  L  ...    0     0   2    6    8         -10    0    0    Playoffs   \n58284  L  ...    0     0   1    2   15         -19    0    0    Playoffs   \n58285  L  ...    0     0   1    0    0          -9    0    0    Playoffs   \n58286  L  ...    0     0   4    1    4         -15    0    0    Playoffs   \n58287  L  ...    0     0   0    0    2          -6    0    0    Playoffs   \n\n                           UID_STG  \n0      2007-0816106127390010700104  \n1      2007-0816106127430010700106  \n2      2007-0816106127410010700109  \n3      2007-0816106127390010700104  \n4      2007-0816106127610010700104  \n...                            ...  \n58283  2008-0916106127380040800111  \n58284  2008-0916106127650040800101  \n58285  2008-0916106127590040800161  \n58286  2008-0916106127570040800171  \n58287  2008-0916106127380040800111  \n\n[58288 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEASON_YEAR</th>\n      <th>PLAYER_ID</th>\n      <th>PLAYER_NAME</th>\n      <th>TEAM_ID</th>\n      <th>TEAM_ABBREVIATION</th>\n      <th>TEAM_NAME</th>\n      <th>GAME_ID</th>\n      <th>GAME_DATE</th>\n      <th>MATCHUP</th>\n      <th>WL</th>\n      <th>...</th>\n      <th>BLK</th>\n      <th>BLKA</th>\n      <th>PF</th>\n      <th>PFD</th>\n      <th>PTS</th>\n      <th>PLUS_MINUS</th>\n      <th>DD2</th>\n      <th>TD3</th>\n      <th>Game_Type</th>\n      <th>UID_STG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-08</td>\n      <td>200759</td>\n      <td>Cedric Simmons</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-08</td>\n      <td>1088</td>\n      <td>Chucky Atkins</td>\n      <td>1610612743</td>\n      <td>DEN</td>\n      <td>Denver Nuggets</td>\n      <td>0010700106</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>DEN @ PHX</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127430010700106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-08</td>\n      <td>201191</td>\n      <td>JamesOn Curry</td>\n      <td>1610612741</td>\n      <td>CHI</td>\n      <td>Chicago Bulls</td>\n      <td>0010700109</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CHI vs. MIL</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127410010700109</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-08</td>\n      <td>1956</td>\n      <td>Ira Newble</td>\n      <td>1610612739</td>\n      <td>CLE</td>\n      <td>Cleveland Cavaliers</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>CLE @ TOR</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127390010700104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-08</td>\n      <td>2743</td>\n      <td>Kris Humphries</td>\n      <td>1610612761</td>\n      <td>TOR</td>\n      <td>Toronto Raptors</td>\n      <td>0010700104</td>\n      <td>2007-10-25T00:00:00</td>\n      <td>TOR vs. CLE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Pre Season</td>\n      <td>2007-0816106127610010700104</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58283</th>\n      <td>2008-09</td>\n      <td>200796</td>\n      <td>Leon Powe</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n    <tr>\n      <th>58284</th>\n      <td>2008-09</td>\n      <td>1888</td>\n      <td>Richard Hamilton</td>\n      <td>1610612765</td>\n      <td>DET</td>\n      <td>Detroit Pistons</td>\n      <td>0040800101</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>DET @ CLE</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15</td>\n      <td>-19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127650040800101</td>\n    </tr>\n    <tr>\n      <th>58285</th>\n      <td>2008-09</td>\n      <td>703</td>\n      <td>Kurt Thomas</td>\n      <td>1610612759</td>\n      <td>SAS</td>\n      <td>San Antonio Spurs</td>\n      <td>0040800161</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>SAS vs. DAL</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127590040800161</td>\n    </tr>\n    <tr>\n      <th>58286</th>\n      <td>2008-09</td>\n      <td>101112</td>\n      <td>Channing Frye</td>\n      <td>1610612757</td>\n      <td>POR</td>\n      <td>Portland Trail Blazers</td>\n      <td>0040800171</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>POR vs. HOU</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127570040800171</td>\n    </tr>\n    <tr>\n      <th>58287</th>\n      <td>2008-09</td>\n      <td>1630</td>\n      <td>Mikki Moore</td>\n      <td>1610612738</td>\n      <td>BOS</td>\n      <td>Boston Celtics</td>\n      <td>0040800111</td>\n      <td>2009-04-18T00:00:00</td>\n      <td>BOS vs. CHI</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Playoffs</td>\n      <td>2008-0916106127380040800111</td>\n    </tr>\n  </tbody>\n</table>\n<p>58288 rows × 36 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mikki Moore\n3.0\n"
     ]
    }
   ],
   "source": [
    "# Reference to sum column values under certain condition.\n",
    "# https://intellipaat.com/community/49/how-do-i-sum-values-in-a-column-that-match-a-given-condition-using-pandas\n",
    "\n",
    "# for currNumRec in (0,totalNumRec,1):\n",
    "# currNumRec = 4\n",
    "# pick by cell in dataframe\n",
    "\n",
    "# Update UID_STG with calculated values  'SEASON_YEAR', 'TEAM_ID', 'GAME_ID'\n",
    "totalNumRec = 58288\n",
    "\n",
    "for currNumRec in range(totalNumRec):\n",
    "    df_TF['UID_STG'].loc[currNumRec] = df_TF['SEASON_YEAR'].loc[currNumRec] + str(df_TF['TEAM_ID'].loc[currNumRec]) +  df_TF['GAME_ID'].loc[currNumRec]\n",
    "\n",
    "\n",
    "display(df_TF['PF'].loc[currNumRec])\n",
    "\n",
    "# gmPTS = df_TF.loc[df_TF[]\n",
    "\n",
    "PIE = (df_TF['PTS'].loc[currNumRec] + df_TF['FGM'].loc[currNumRec] + df_TF['FTM'].loc[currNumRec] \\\n",
    "    - df_TF['FGA'].loc[currNumRec] - df_TF['FTA'].loc[currNumRec] \\\n",
    "    + df_TF['DREB'].loc[currNumRec] + (0.5 * df_TF['OREB'].loc[currNumRec]) \\\n",
    "    + df_TF['AST'].loc[currNumRec] + df_TF['STL'].loc[currNumRec] + (0.5 * df_TF['BLK'].loc[currNumRec]) \\\n",
    "    - df_TF['PF'].loc[currNumRec] - df_TF['TOV'].loc[currNumRec])\n",
    "\n",
    "\n",
    "display(df_TF)\n",
    "print(df_TF['PLAYER_NAME'].loc[currNumRec])\n",
    "print(PIE)\n",
    "    # PTS + FGM + FTM - FGA - FTA + DREB + (.5 * OREB) + AST + STL + (.5 * BLK) - PF - TO) / (GmPTS + GmFGM + GmFTM - GmFGA - GmFTA + GmDREB + (.5 * GmOREB) + GmAST + GmSTL + (.5 * GmBLK) - GmPF - GmTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "58287\n58286\n"
     ]
    }
   ],
   "source": [
    "print(totalNumRec)\n",
    "print(currNumRec)"
   ]
  },
  {
   "source": [
    "## Section : Remove (Stage 1) from dataframe the unwanted numerical/categorical features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather current list of features\n",
    "numerical_Features = df_TF.columns.tolist()\n",
    "\n",
    "# All possible features\n",
    "# ['SEASON_YEAR', 'PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_ID', 'GAME_DATE', 'MATCHUP', 'WL', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD', 'PTS', 'PLUS_MINUS', 'DD2', 'TD3', 'Game_Type']\n",
    "\n",
    "for i in categorical_Features: \n",
    "    numerical_Features.remove(i)\n",
    "\n",
    "# Lists unwanted features\n",
    "unwanted_numerical_Features = ['PLAYER_ID', 'TEAM_ID', 'GAME_ID']\n",
    "unwanted_categorical_Features = ['PLAYER_NAME', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_DATE', 'MATCHUP']\n",
    "unwanted_list_01 = unwanted_numerical_Features + unwanted_categorical_Features\n",
    "X_headers_list = df_TF.columns.tolist()\n",
    "\n",
    "for i in unwanted_list_01:\n",
    "    X_headers_list.remove(i)\n",
    "\n",
    "# Reset new dataframe with desired features\n",
    "df_Reduced = df_TF[X_headers_list]\n",
    "\n",
    "# Remaining attributes\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(X_headers_list)"
   ]
  },
  {
   "source": [
    "## Section : Transform categorical feature (WL) using value replace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_categorical_Features = ['WL', 'Game_Type']\n",
    "cleanupValue = {'WL': {'W': 1, 'L': 0}, 'Game_Type': {'Pre Season': 0, 'Regular Season': 1, 'Playoffs': 2}}\n",
    "df_Reduced = df_Reduced.replace(cleanupValue)\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Reduced)"
   ]
  },
  {
   "source": [
    "## Section : Transform categorical features using LabelEncoder\n",
    "\n",
    "This will work with the reminding categorical values as there is a hierarchy for \n",
    "\n",
    "'SEASON_YEAR' - the more recent the season the more relevant it is where as older data is less valuable\n",
    "\n",
    "'Game_Type' - need to think about this but assume regular season is more important"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features to encode\n",
    "e_categorical = categorical_Features\n",
    "\n",
    "for i in unwanted_categorical_Features:\n",
    "    e_categorical.remove(i)\n",
    "\n",
    "for j in cleaned_categorical_Features:\n",
    "    e_categorical.remove(j)\n",
    "\n",
    "# Reset variable\n",
    "categorical_Features = df_Reduced.dtypes[df_Reduced.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "# cat_list = ['Gender','Education_Level','Marital_Status','Income_Category','Card_Category']\n",
    "# cat_list_code = ['Gender_code','Education_Level_code','Marital_Status_code','Income_Category_code','Card_Category_code']\n",
    "\n",
    "df_Encoded = df_Reduced\n",
    "# df_Encoded = df_Reduced[e_categorical]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LabelEncoding on e_categorical features\n",
    "\n",
    "for k in e_categorical:\n",
    "    val_A = k\n",
    "    val_B = k + '_code'\n",
    "    df_Encoded[(val_B)] = lb_make.fit_transform(df_Encoded[val_A])\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Encoded) #Results in appending a new column to df"
   ]
  },
  {
   "source": [
    "## Using OneHotEncoding (Not Working)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_cat_features = 'Sex'\n",
    "# df_cat = pd.DataFrame(df[sel_cat_features])\n",
    "# df_cat_dummies = pd.get_dummies(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_num_features.remove(sel_cat_features)\n",
    "# df_sel_features = pd.concat([df[sel_num_features], df_cat_dummies], axis=1)\n",
    "# df_sel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(categorical_Features)\n",
    "# print(unwanted_categorical_Features)\n",
    "# display(df_Encoded)\n",
    "# display(df_Reduced[e_categorical])\n",
    "# print(e_categorical)\n",
    "# display(df_Reduced)\n"
   ]
  },
  {
   "source": [
    "## Section 4: Enhancing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unadjusted Player Efficientcy Rating (uPER)\n",
    "# uPER = (1 / MIN) *\n",
    "#      [ FG3M\n",
    "#      + (2/3) * AST\n",
    "#      + (2 - factor * (team_AST / team_FG)) * FG\n",
    "#      + (FT *0.5 * (1 + (1 - (team_AST / team_FG)) + (2/3) * (team_AST / team_FG)))\n",
    "#      - VOP * TOV\n",
    "#      - VOP * DRB% * (FGA - FG)\n",
    "#      - VOP * 0.44 * (0.44 + (0.56 * DRB%)) * (FTA - FT)\n",
    "#      + VOP * (1 - DRB%) * (TRB - ORB)\n",
    "#      + VOP * DRB% * ORB\n",
    "#      + VOP * STL\n",
    "#      + VOP * DRB% * BLK\n",
    "#      - PF * ((lg_FT / lg_PF) - 0.44 * (lg_FTA / lg_PF) * VOP) ]\n",
    "\n",
    "# # Insert gameType column and list as one of the values in gameTypeListed\n",
    "#         df_gamelogs_players_currSeason['Game_Type'] = gameType\n",
    "#         if countFirstYear == 0:\n",
    "#             df_gamelogs_players = df_gamelogs_players_currSeason\n",
    "#             countFirstYear = 1\n",
    "#         else:\n",
    "#             # df_gamelogs_players = np.concatenate([df_gamelogs_players, df_gamelogs_players_currSeason])\n",
    "#             df_gamelogs_players = pd.concat([df_gamelogs_players, df_gamelogs_players_currSeason],ignore_index=True)\n",
    "#             # df_gamelogs_players = df_gamelogs_players.append(df_gamelogs_players_currSeason)\n"
   ]
  },
  {
   "source": [
    "# Section : \n",
    "\n",
    "Define column as TARGET variable\n",
    "\n",
    "Remove (Stage 2) from dataframe the featuree (categorical, Target, and other unwanted)\n",
    "\n",
    "Separating the dataframe by gameTypeListed ('Pre Season', 'Regular Season', 'Playoffs')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure variables\n",
    "# gameTypeListed = ['Pre Season', 'Regular Season', 'Playoffs']\n",
    "gameTypeListed_code = [0, 1, 2]\n",
    "Y_headers_list1 = ['WL', 'Game_Type']\n",
    "Y_headers_list2 = ['WL']\n",
    "e_categorical = e_categorical + Y_headers_list2\n",
    "\n",
    "# Define the current list of features\n",
    "X_headers_list = df_Encoded.columns.tolist()\n",
    "\n",
    "# Remove LabelEncoded categorical features\n",
    "for k in e_categorical:\n",
    "    X_headers_list.remove(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_Reduced2 = df_Encoded[X_headers_list]\n",
    "df_Y_Reduced2 = df_Encoded[Y_headers_list1]\n",
    "\n",
    "for gameType in gameTypeListed_code:\n",
    "    is_gameType_X = df_X_Reduced2['Game_Type']==gameType\n",
    "    is_gameType_Y = df_Y_Reduced2['Game_Type']==gameType\n",
    "    if gameType == 0:\n",
    "        df_X_PreSeason = df_X_Reduced2[is_gameType_X]\n",
    "        df_Y_PreSeason = df_Y_Reduced2[is_gameType_Y]\n",
    "        df_Y_PreSeason = df_Y_PreSeason[Y_headers_list2]\n",
    "    elif gameType == 1:\n",
    "        df_X_RegularSeason = df_X_Reduced2[is_gameType_X]\n",
    "        df_Y_RegularSeason = df_Y_Reduced2[is_gameType_Y]\n",
    "        df_Y_RegularSeason = df_Y_RegularSeason[Y_headers_list2]\n",
    "    elif gameType == 2:\n",
    "        df_X_Playoffs = df_X_Reduced2[is_gameType_X]\n",
    "        df_Y_Playoffs = df_Y_Reduced2[is_gameType_Y]\n",
    "        df_Y_Playoffs = df_Y_Playoffs[Y_headers_list2]\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print(\"\")\n",
    "    print(\"Pre Season\")\n",
    "    display(df_X_PreSeason)\n",
    "    display(df_Y_PreSeason)\n",
    "    print(\"\")\n",
    "    print(\"Regular Season\")\n",
    "    display(df_X_RegularSeason)\n",
    "    display(df_Y_RegularSeason)\n",
    "    print(\"\")\n",
    "    print(\"Playoffs\")\n",
    "    display(df_X_Playoffs)\n",
    "    display(df_Y_Playoffs)"
   ]
  },
  {
   "source": [
    "# Section 5: Analysis - Heat Maps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.set_context(\"paper\", font_scale=1)\n",
    "\n",
    "# sns.heatmap(df.corr(), annot=True, cmap='Blues',vmin=-1, vmax=1, square=False, linewidths=0.5)\n",
    "print(\"\")\n",
    "print(\"Pre Season\")\n",
    "sns.heatmap(df_X_PreSeason.corr(), annot=True, cmap='Blues',vmin=-1, vmax=1, square=False, linewidths=0.5)\n",
    "# display(df_X_PreSeason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.set_context(\"paper\", font_scale=1)\n",
    "print(\"\")\n",
    "print(\"Regular Season\")\n",
    "sns.heatmap(df_X_RegularSeason.corr(), annot=True, cmap='Blues',vmin=-1, vmax=1, square=False, linewidths=0.5)\n",
    "# display(df_X_RegularSeason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.set_context(\"paper\", font_scale=1)\n",
    "print(\"\")\n",
    "print(\"Playoffs\")\n",
    "sns.heatmap(df_X_Playoffs.corr(), annot=True, cmap='Blues',vmin=-1, vmax=1, square=False, linewidths=0.5)\n",
    "# display(df_X_Playoffs)"
   ]
  },
  {
   "source": [
    "## Section : Remove additional unwanted fields based on Heat Map / Correlation Matrix\n",
    "\n",
    "## NOT ACTIVE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted/useless attributes\n",
    "unwanted_list_02 = []\n",
    "\n",
    "for k in unwanted_list_02:\n",
    "    X_headers_list.remove(k)\n",
    "\n",
    "# Remaining attributes\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(X_headers_list)"
   ]
  },
  {
   "source": [
    "## Section : Re-check Heat Map / Correlation Matrix\n",
    "\n",
    "## NOT ACTIVE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Reuse code for previous Heat Maps"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Section : Modeling and Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Section : Prepare train and test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a season \n",
    "# gameTypeListed = ['Pre Season', 'Regular Season', 'Playoffs']\n",
    "# gameTypeListed_code = [1, 2, 0]\n",
    "\n",
    "gameType = 2\n",
    "if gameType == 0:\n",
    "    X = df_X_PreSeason\n",
    "    Y = df_Y_PreSeason\n",
    "elif gameType == 1:\n",
    "    X = df_X_RegularSeason\n",
    "    Y = df_Y_RegularSeason\n",
    "elif gameType == 2:\n",
    "    X = df_X_Playoffs\n",
    "    Y = df_Y_Playoffs\n",
    "\n",
    "# Split the code into training and test dataset 0.7/0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = test_size_val, random_state = random_state_val)\n",
    "\n",
    "# Validate the split at a high level\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print('Season Type: ', gameType)\n",
    "    df_Encoded.to_csv('DAT205_Output_All.csv') \n",
    "    X_train.to_csv('DAT205_Output_Split_X_train.csv') \n",
    "    X_test.to_csv('DAT205_Output_Split_X_test.csv') \n",
    "    Y_train.to_csv('DAT205_Output_Split_Y_train.csv') \n",
    "    Y_test.to_csv('DAT205_Output_Split_Y_test.csv') \n",
    "    display(X_train)\n",
    "    display(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(X)\n",
    "    display(Y)"
   ]
  },
  {
   "source": [
    "# Section : Apply Logistic Regression on the split train/test dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isnan(df_Encoded.any())\n",
    "# np.isfinite(df_Encoded.all())\n",
    "\n",
    "# np.any(np.isnan(df_Encoded))\n",
    "# np.all(np.isfinite(df_Encoded))"
   ]
  },
  {
   "source": [
    "# Notes\n",
    "# LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "#                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "#                    multi_class='warn', n_jobs=None, penalty='l2',\n",
    "#                    random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
    "#                    warm_start=False)\n",
    "\n",
    "# Create the model\n",
    "LogRegM = LogisticRegression(C=1, solver='liblinear', random_state = random_state_val)\n",
    "\n",
    "# Train the model\n",
    "LogRegM.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict using test data\n",
    "Y_pred = LogRegM.predict(X_test)\n",
    "\n",
    "# Y_pred = pd.DataFrame(Y_pred, columns = [\"WL_code\"])\n",
    "# df = pd.DataFrame(data=numpy_data, index=[\"row1\", \"row2\"], columns=[\"column1\", \"column2\"])\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(Y_pred)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Confusion Matrix Analysis Notes\n",
    "https://www.google.com/search?q=confusion+matrix&rlz=1C1GCEA_enCA849CA849&oq=confusion+&aqs=chrome.1.69i57j0i433l2j0j0i433j0l5.2966j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "## Analysis score notes \n",
    "https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Compute your model’s analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_LogRegM = accuracy_score(Y_test, Y_pred)\n",
    "f1_score_LogRegM = f1_score(Y_test, Y_pred)\n",
    "recall_score_LogRegM = recall_score(Y_test, Y_pred)\n",
    "precision_score_LogRegM = precision_score(Y_test, Y_pred)\n",
    "classification_report_LogRegM = classification_report(Y_test, Y_pred)\n",
    "confusion_matrix_LogRegM = confusion_matrix(Y_test, Y_pred)\n",
    "cm = confusion_matrix_LogRegM\n",
    "sensitivity_LogRegM = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity_LogRegM = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print('Accuracy:', numFormat.format(accuracy_score_LogRegM))\n",
    "    print('F1 score:', numFormat.format(f1_score_LogRegM))\n",
    "    print('Recall:', numFormat.format(recall_score_LogRegM))\n",
    "    print('Precision:', numFormat.format(precision_score_LogRegM))\n",
    "    print('Sensitivity : ', numFormat.format(sensitivity_LogRegM))\n",
    "    print('Specificity : ', numFormat.format(specificity_LogRegM))\n",
    "    print('\\n clasification report:\\n', classification_report_LogRegM)\n",
    "    print('\\n confussion matrix:\\n',confusion_matrix_LogRegM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importance = LogRegM.coef_[0]\n",
    "array_importance=[]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    array_importance.append(v)\n",
    "    # print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# # Convert to dataframe feature_importances results\n",
    "df_feature_importance_values = pd.DataFrame(array_importance)\n",
    "df_feature_importance_values.rename(columns={0:'Feature Importance'}, inplace=True)\n",
    "\n",
    "# # Convert to dataframe feature labels\n",
    "df_feature_names = pd.DataFrame(list(X.columns))\n",
    "df_feature_names.rename(columns={0:'Feature'}, inplace=True)\n",
    "\n",
    "# # Merge the dataframes for feature labels and feature_importances results\n",
    "df_feature_importance_LogRegM = pd.concat([df_feature_names, df_feature_importance_values], axis=1)\n",
    "# df_feature_importance\n",
    "\n",
    "df_feature_importance_LogRegM.sort_values('Feature Importance', ascending=False, inplace=True)\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    df_feature_importance_LogRegM"
   ]
  },
  {
   "source": [
    "## Section :  Apply Decision Tree Classifier on the split train/test dataset\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "DTM = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "DTM.fit(X_train, Y_train)\n",
    "\n",
    "# Predict using test data\n",
    "Y_pred = DTM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_DTM = accuracy_score(Y_test, Y_pred)\n",
    "f1_score_DTM = f1_score(Y_test, Y_pred)\n",
    "recall_score_DTM = recall_score(Y_test, Y_pred)\n",
    "precision_score_DTM = precision_score(Y_test, Y_pred)\n",
    "classification_report_DTM = classification_report(Y_test, Y_pred)\n",
    "confusion_matrix_DTM = confusion_matrix(Y_test, Y_pred)\n",
    "cm = confusion_matrix_DTM\n",
    "sensitivity_DTM = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity_DTM = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print('Accuracy:', numFormat.format(accuracy_score_DTM))\n",
    "    print('F1 score:', numFormat.format(f1_score_DTM))\n",
    "    print('Recall:', numFormat.format(recall_score_DTM))\n",
    "    print('Precision:', numFormat.format(precision_score_DTM))\n",
    "    print('Sensitivity : ', numFormat.format(sensitivity_DTM))\n",
    "    print('Specificity : ', numFormat.format(specificity_DTM))\n",
    "    print('\\n clasification report:\\n', classification_report_DTM)\n",
    "    print('\\n confussion matrix:\\n',confusion_matrix_DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importance = DTM.feature_importances_\n",
    "array_importance=[]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    array_importance.append(v)\n",
    "    # print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# # Convert to dataframe feature_importances results\n",
    "df_feature_importance_values = pd.DataFrame(array_importance)\n",
    "df_feature_importance_values.rename(columns={0:'Feature Importance'}, inplace=True)\n",
    "\n",
    "# # Convert to dataframe feature labels\n",
    "df_feature_names = pd.DataFrame(list(X.columns))\n",
    "df_feature_names.rename(columns={0:'Feature'}, inplace=True)\n",
    "\n",
    "# # Merge the dataframes for feature labels and feature_importances results\n",
    "df_feature_importance_DTM = pd.concat([df_feature_names, df_feature_importance_values], axis=1)\n",
    "# df_feature_importance\n",
    "\n",
    "df_feature_importance_DTM.sort_values('Feature Importance', ascending=False, inplace=True)\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    df_feature_importance_DTM"
   ]
  },
  {
   "source": [
    "## Section : Apply Random Forest Classifier on the split train/test dataset\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "RFM = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "RFM.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict using test data\n",
    "Y_pred = RFM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Y_train)\n",
    "display(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_RFM = accuracy_score(Y_test, Y_pred)\n",
    "f1_score_RFM = f1_score(Y_test, Y_pred)\n",
    "recall_score_RFM = recall_score(Y_test, Y_pred)\n",
    "precision_score_RFM = precision_score(Y_test, Y_pred)\n",
    "classification_report_RFM = classification_report(Y_test, Y_pred)\n",
    "confusion_matrix_RFM = confusion_matrix(Y_test, Y_pred)\n",
    "cm = confusion_matrix_RFM\n",
    "sensitivity_RFM = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity_RFM = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print('Accuracy:', numFormat.format(accuracy_score_RFM))\n",
    "    print('F1 score:', numFormat.format(f1_score_RFM))\n",
    "    print('Recall:', numFormat.format(recall_score_RFM))\n",
    "    print('Precision:', numFormat.format(precision_score_RFM))\n",
    "    print('Sensitivity : ', numFormat.format(sensitivity_RFM))\n",
    "    print('Specificity : ', numFormat.format(specificity_RFM))\n",
    "    print('\\n clasification report:\\n', classification_report_RFM)\n",
    "    print('\\n confussion matrix:\\n',confusion_matrix_RFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importance = RFM.feature_importances_\n",
    "array_importance=[]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    array_importance.append(v)\n",
    "    # print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# # Convert to dataframe feature_importances results\n",
    "df_feature_importance_values = pd.DataFrame(array_importance)\n",
    "df_feature_importance_values.rename(columns={0:'Feature Importance'}, inplace=True)\n",
    "\n",
    "# # Convert to dataframe feature labels\n",
    "df_feature_names = pd.DataFrame(list(X.columns))\n",
    "df_feature_names.rename(columns={0:'Feature'}, inplace=True)\n",
    "\n",
    "# # Merge the dataframes for feature labels and feature_importances results\n",
    "df_feature_importance_RFM = pd.concat([df_feature_names, df_feature_importance_values], axis=1)\n",
    "# df_feature_importance\n",
    "\n",
    "df_feature_importance_RFM.sort_values('Feature Importance', ascending=False, inplace=True)\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    df_feature_importance_RFM"
   ]
  },
  {
   "source": [
    "# Section : Cross Validation Scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = random_state_val\n",
    "# seed = 0\n",
    "\n",
    "loan_models = []\n",
    "# loan_models.append(('Logistic Regression', LogisticRegression()))\n",
    "loan_models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "# loan_models.append(('KNN', KNeighborsClassifier()))\n",
    "# loan_models.append(('Linear Discriminant Analysis', LinearDiscriminantAnalysis()))\n",
    "# loan_models.append(('Gaussian', GaussianNB()))\n",
    "# loan_models.append(('SVM', SVC()))\n",
    "loan_models.append(('Random Forest', RandomForestClassifier()))\n",
    "\n",
    "cross_val_scores = []\n",
    "model_keys = []\n",
    "\n",
    "df_cross_val_score = []\n",
    "df_cross_val_score_headers = [0,1,2,3]\n",
    "df_cross_val_score = pd.DataFrame (df_cross_val_score, columns = df_cross_val_score_headers)\n",
    "\n",
    "# VALIDATION CODE \n",
    "# if debug_active == 'yes':\n",
    "#     nullFieldAnalysis(df_cross_val_score)\n",
    "\n",
    "df_Addscore = []\n",
    "scoring = 'accuracy'\n",
    "for model_key, loan_model in loan_models:\n",
    "    kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    cross_val_score = model_selection.cross_val_score(loan_model, X_train, Y_train.values.ravel(), cv=kfold, scoring=scoring)\n",
    "    cross_val_scores.append(cross_val_score)\n",
    "    model_keys.append(model_key)\n",
    "    msg = \"%s: cross val mean -> %f , cross val std -> %f, kfold variance -> %f\" % (model_key, cross_val_score.mean(), cross_val_score.std(), cross_val_score.var())\n",
    "    df_Addscore = pd.Series([model_key, cross_val_score.mean(), cross_val_score.std(), cross_val_score.var()])\n",
    "    df_cross_val_score = df_cross_val_score.append(df_Addscore, ignore_index=True)\n",
    "    print(msg)\n",
    "\n",
    "df_cross_val_score.columns = ['Model_Key','Cross_Value_Score_Mean','Cross_Value_Score_STD','Cross_Value_Score_Var']\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    print(\"\")\n",
    "    print(\"VALIDATION RESULT\")\n",
    "    display(df_cross_val_score)\n",
    "    print(model_keys)\n",
    "    print(cross_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WORK IN PROGRESS\n",
    "\n",
    "# # boxplot algorithm comparison\n",
    "\n",
    "# # plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "# # fig = plt.figure()\n",
    "# # fig.suptitle('Model Comparison')\n",
    "# # ax = fig.add_subplot(111)\n",
    "# # sns.boxplot(x = model_keys, y=cross_val_scores, palette = 'Blues')\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.style.use('ggplot')\n",
    "# plotX = pd.Series(model_keys)\n",
    "# plotY = pd.Series(cross_val_scores)\n",
    "\n",
    "# df = pd.DataFrame({\"model_keys\" : plotX, \"cross_val_scores\" : plotY})\n",
    "# # plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "# # fig = plt.figure()\n",
    "# # fig.suptitle('Model Comparison')\n",
    "# # ax = fig.add_subplot(111)\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# sns.boxplot(data=df, palette = 'Blues')\n",
    "\n",
    "\n",
    "\n",
    "# # plt.style.use('ggplot')\n",
    "# # dummyData.groupby(['quarter', 'brand'])\\\n",
    "# #       .brand.count().unstack().plot.bar(legend=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "\n",
    "print(model_keys)\n",
    "print(cross_val_scores)\n",
    "\n",
    "\n",
    "print(plotX)\n",
    "print(plotY)"
   ]
  },
  {
   "source": [
    "# Section : Summary Report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table of metric analysis\n",
    "df_Metrics = []\n",
    "\n",
    "df_Metrics_headers = [0,1,2,3,4,5,6]\n",
    "df_Metrics = pd.DataFrame (df_Metrics, columns = df_Metrics_headers)\n",
    "\n",
    "# df_AddModel = pd.Series(['Logistic Regression', accuracy_score_LogRegM,f1_score_LogRegM,recall_score_LogRegM,precision_score_LogRegM,sensitivity_LogRegM,specificity_LogRegM])\n",
    "# df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "df_AddModel = pd.Series(['Decision Tree',accuracy_score_DTM,f1_score_DTM,recall_score_DTM,precision_score_DTM,sensitivity_DTM,specificity_DTM])\n",
    "df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "# df_AddModel = pd.Series(['K Nearest Neighbors',accuracy_score_KNNM,f1_score_KNNM,recall_score_KNNM,precision_score_KNNM,sensitivity_KNNM,specificity_KNNM])\n",
    "# df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "# df_AddModel = pd.Series(['Linear Discriminant Analysis',accuracy_score_LDAM,f1_score_LDAM,recall_score_LDAM,precision_score_LDAM,sensitivity_LDAM,specificity_LDAM])\n",
    "# df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "# df_AddModel = pd.Series(['Gaussian Naive Bayes',accuracy_score_GNBM,f1_score_GNBM,recall_score_GNBM,precision_score_GNBM,sensitivity_GNBM,specificity_GNBM])\n",
    "# df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "# df_AddModel = pd.Series(['SVM',accuracy_score_SVMM,f1_score_SVMM,recall_score_SVMM,precision_score_SVMM,sensitivity_SVMM,specificity_SVMM])\n",
    "# df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "df_AddModel = pd.Series(['Random Forest',accuracy_score_RFM,f1_score_RFM,recall_score_RFM,precision_score_RFM,sensitivity_RFM,specificity_RFM])\n",
    "df_Metrics = df_Metrics.append(df_AddModel, ignore_index=True)\n",
    "\n",
    "df_Metrics.columns = ['Model','Accuracy','F1 score','Recall','Precision','Sensitivity','Specificity']\n",
    "\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Metrics)\n",
    "\n",
    "# Join dataframes for Metrics and cross_val_scores\n",
    "df_Summary = pd.concat([df_Metrics,df_cross_val_score], axis=1)\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up columns by dropping columns of duplicate data (Model_Key)\n",
    "df_Summary.drop(['Model_Key'], axis=1, inplace=True)\n",
    "# df_Summary.drop(columns=['Model_Key'], inplace=True)\n",
    "# VALIDATION CODE \n",
    "if debug_active == 'yes':\n",
    "    display(df_Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"================= Results Summary ==================\\n\")\n",
    "\n",
    "print(\"==================== Attributes ======================\")\n",
    "print('----------------- Removed attributes -----------------')\n",
    "display(unwanted_list_01)\n",
    "print('\\n------ Removed attributes - Heat Map / Correlation Matrix ---- ')\n",
    "display(unwanted_list_02)\n",
    "\n",
    "print('\\n------------------- Applied attributes --------------------')\n",
    "display(X_headers_list)\n",
    "\n",
    "print(\"\\n ================= Model Analysis Summary ==================\\n\")\n",
    "display(df_Summary)\n",
    "\n",
    "print('\\n\\n----------------- Logistic Regression --------------------')\n",
    "print('\\n clasification report:\\n', classification_report_LogRegM)\n",
    "print('\\n confussion matrix:\\n',confusion_matrix_LogRegM)\n",
    "print(\"\\nFeature Importance\")\n",
    "display(df_feature_importance_LogRegM)\n",
    "\n",
    "print('\\n\\n-------------------- Decision Tree -----------------------\\n')\n",
    "print('\\n clasification report:\\n', classification_report_DTM)\n",
    "print('\\n confussion matrix:\\n',confusion_matrix_DTM)\n",
    "print(\"\\nFeature Importance\")\n",
    "display(df_feature_importance_DTM)\n",
    "\n",
    "# print('\\n\\n------------- Linear Discriminant Analysis ---------------\\n')\n",
    "# print('\\n clasification report:\\n', classification_report_LDAM)\n",
    "# print('\\n confussion matrix:\\n',confusion_matrix_LDAM)\n",
    "# print(\"\\nFeature Importance\")\n",
    "# display(df_feature_importance_LDAM)\n",
    "\n",
    "print('\\n\\n-------------------- Random Forest -----------------------\\n')\n",
    "print('\\n clasification report:\\n', classification_report_RFM)\n",
    "print('\\n confussion matrix:\\n',confusion_matrix_RFM)\n",
    "print(\"\\nFeature Importance\")\n",
    "display(df_feature_importance_RFM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_took = time.time() - start_time\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(f\"Total Runtime: {hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}